{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdelinea/anaconda3/envs/Env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Required Packages\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import importlib.util\n",
    "from typing import *\n",
    "from tqdm import tqdm \n",
    "from typing import List\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "import torch as nn\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification,Trainer, TrainingArguments, PreTrainedModel,AutoConfig,DataCollatorWithPadding\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "from JS_Architects import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We will use Architects model\n",
    "\n",
    "1) Implement Custom pipeline, no prompting just prediction with shrekking of the embedding \n",
    "\n",
    "2) Automated Forsequence Classification\n",
    "    1) No prompting\n",
    "    2) Prompt: \"Classify with labels encode in binary\"\n",
    "    3) Prompt: \"Clasify with list label: [\"depth\",...]\"\n",
    "    4) Prompt \"Classify with list label: [\"depth\",...]. Depth represents..., Containment represents....\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Pipeline \n",
    "\n",
    "## 1. Prepare Data\n",
    "\n",
    "### Load \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"perceptions_training.json\", \"r\") as f:\n",
    "    dic_training = json.load(f)\n",
    "\n",
    "with open(\"perceptions_training_full.json\", \"r\") as f:\n",
    "    dic_training_full = json.load(f)\n",
    "\n",
    "with open(\"perceptions_testing.json\", \"r\") as f:\n",
    "    dic_testing = json.load(f)\n",
    "\n",
    "label_list = [\n",
    "    \"containment\",\n",
    "    \"depth\",\n",
    "    \"symmetry\",\n",
    "    \"categorical\",\n",
    "    \"spatial-Orientation\",\n",
    "    \"spatial-Ordinal\",\n",
    "    \"similarity\",\n",
    "    \"quantitative\",\n",
    "    \"replication\",\n",
    "    \"figure-Ground\",\n",
    "    \"continuity\",\n",
    "    \"size\",\n",
    "    \"closure\",\n",
    "    \"centroid\",\n",
    "    \"topological\",\n",
    "    \"motion\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_multilabel_classification(\n",
    "    dic_training,\n",
    "    instruction,\n",
    "    label_list,\n",
    "    inp_prefix=\"<I>\",\n",
    "    out_prefix=\"<O>\",\n",
    "    arr_sep=\"\\n\",\n",
    "    exa_sep=\"\\n---\\n\",\n",
    "    bos_token=\"<|begin_of_text|>\",\n",
    "    eos_token=\"<|end_of_text|>\"\n",
    "):\n",
    "    llama_data = []\n",
    "\n",
    "    # Create a mapping from label to index\n",
    "    label_to_index = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    for entry_id, content in dic_training.items():\n",
    "        # Extract perceptions (labels) and encode them as a binary vector\n",
    "        perceptions = content.get(\"perceptions\", [])\n",
    "        label_vector = labels_to_binary(label_list, perceptions)\n",
    "\n",
    "        # Combine train and test examples\n",
    "        examples = content.get(\"example\", {}).get(\"train\", []) + content.get(\"example\", {}).get(\"test\", [])\n",
    "\n",
    "        # Format examples into a single input string\n",
    "        formatted_examples = []\n",
    "        for example in examples:\n",
    "            input_data = f\"{inp_prefix}{format_array(example['input'], arr_sep)}\"\n",
    "            output_data = f\"{out_prefix}{format_array(example['output'], arr_sep)}{eos_token}\"\n",
    "            formatted_examples.append(f\"{input_data}{exa_sep}{output_data}\")\n",
    "\n",
    "        # Combine all examples into one input text and prepend the BOS token\n",
    "        combined_text = f\"{exa_sep.join(formatted_examples)}\"\n",
    "\n",
    "        # Add the structured data for fine-tuning\n",
    "        llama_data.append({\n",
    "            \"instruction\": f\"{instruction}\",\n",
    "            \"input\": combined_text,\n",
    "            \"output\": label_vector,  # Multi-label as binary vector\n",
    "        })\n",
    "\n",
    "    return llama_data\n",
    "\n",
    "def format_array(array, arr_sep=\"\\n\"):\n",
    "    \"\"\"\n",
    "    Helper function to format a 2D array into a string with row-wise separation.\n",
    "    \"\"\"\n",
    "    return arr_sep.join([\" \".join(map(str, row)) for row in array])\n",
    "\n",
    "def labels_to_binary(label_list, input_labels):\n",
    "    \"\"\"\n",
    "    Convert perceptions into a binary vector based on the label list.\n",
    "    Handles both single strings and lists of strings for input_labels.\n",
    "    \"\"\"\n",
    "    # Ensure input_labels is treated as a list\n",
    "    if isinstance(input_labels, str):\n",
    "        input_labels = [input_labels]\n",
    "    \n",
    "    # Create a set of lowercase input labels\n",
    "    input_set = set(label.lower() for label in input_labels)\n",
    "    \n",
    "    # Generate the binary vector\n",
    "    return [1 if label.lower() in input_set else 0 for label in label_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Classify the sequence of input-output pairs based on the following categories: containment, depth, symmetry, categorical, spatial-Orientation, spatial-Ordinal, similarity, quantitative, replication, figure-Ground, continuity, size, closure, centroid, topological, motion.',\n",
       " 'input': '<I>8 6\\n6 4\\n---\\n<O>8 6 8 6 8 6\\n6 4 6 4 6 4\\n6 8 6 8 6 8\\n4 6 4 6 4 6\\n8 6 8 6 8 6\\n6 4 6 4 6 4<|end_of_text|>\\n---\\n<I>7 9\\n4 3\\n---\\n<O>7 9 7 9 7 9\\n4 3 4 3 4 3\\n9 7 9 7 9 7\\n3 4 3 4 3 4\\n7 9 7 9 7 9\\n4 3 4 3 4 3<|end_of_text|>\\n---\\n<I>3 2\\n7 8\\n---\\n<O>3 2 3 2 3 2\\n7 8 7 8 7 8\\n2 3 2 3 2 3\\n8 7 8 7 8 7\\n3 2 3 2 3 2\\n7 8 7 8 7 8<|end_of_text|>',\n",
       " 'output': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = (\n",
    "    \"Classify the sequence of input-output pairs based on the following categories: \"\n",
    "    + \", \".join(label_list)\n",
    "    + \".\"\n",
    ")\n",
    "\n",
    "llama_data = prepare_data_for_multilabel_classification(\n",
    "    dic_training, # dic_training_full\n",
    "    instruction,\n",
    "    label_list)\n",
    "\n",
    "llama_data_list_testing = prepare_data_for_multilabel_classification(\n",
    "    dic_testing,\n",
    "    instruction,\n",
    "      label_list)\n",
    "\n",
    "# Dict\n",
    "llama_data_dict = {\n",
    "    \"instruction\": [item[\"instruction\"] for item in llama_data],\n",
    "    \"input\": [item[\"input\"] for item in llama_data],\n",
    "    \"output\": [item[\"output\"] for item in llama_data],\n",
    "}\n",
    "\n",
    "# Restructure llama_data\n",
    "llama_data_dict_testing = {\n",
    "    \"instruction\": [item[\"instruction\"] for item in llama_data_list_testing],\n",
    "    \"input\": [item[\"input\"] for item in llama_data_list_testing],\n",
    "    \"output\": [item[\"output\"] for item in llama_data_list_testing],\n",
    "}\n",
    "\n",
    "# Dataset\n",
    "llama_data_dataset = Dataset.from_dict(llama_data_dict)\n",
    "llama_data_dataset_testing = Dataset.from_dict(llama_data_dict_testing)\n",
    "\n",
    "llama_data_dataset_testing[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we run out of memory we used 3B parameter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B\"\n",
    "                                             #,torch_dtype=torch.float16\n",
    "                                             )\n",
    "\n",
    "print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Shrink the tokenizer and embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>', 'pad_token': '[PAD]', 'additional_special_tokens': ['<I>', '<O>', '\\n', '\\n---\\n']}\n",
      "Vocabulary Size: 128261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128261, 3072)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {\n",
    "    \"input\": \"<I>\",\n",
    "    \"output\": \"<O>\",\n",
    "    \"array_sep\": \"\\n\",\n",
    "    \"example_sep\": \"\\n---\\n\",\n",
    "    \"eos_token\": \"<|end_of_text|>\",\n",
    "    \"bos_token\": \"<|begin_of_text|>\",\n",
    "    \"pad_token\": \"[PAD]\"\n",
    "}\n",
    "\n",
    "# Add special tokens\n",
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": [\n",
    "        special_tokens_dict[\"input\"],\n",
    "        special_tokens_dict[\"output\"],\n",
    "        special_tokens_dict[\"array_sep\"],\n",
    "        special_tokens_dict[\"example_sep\"]\n",
    "    ],\n",
    "    \"eos_token\": special_tokens_dict[\"eos_token\"],\n",
    "    \"bos_token\": special_tokens_dict[\"bos_token\"],\n",
    "    \"pad_token\": special_tokens_dict[\"pad_token\"]\n",
    "})\n",
    "\n",
    "# Set the tokenizer pad token explicitly\n",
    "tokenizer.pad_token = special_tokens_dict[\"pad_token\"]\n",
    "\n",
    "# Check the updated tokens\n",
    "print(f\"Special Tokens: {tokenizer.special_tokens_map}\")\n",
    "print(f\"Vocabulary Size: {len(tokenizer)}\")\n",
    "\n",
    "# Resize model embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423226"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_corpus_for_shrinking(hf_dataset):\n",
    "    \"\"\"\n",
    "    Concatenate the 'input' + 'instruction' from the dataset\n",
    "    to ensure all relevant tokens appear.\n",
    "    \"\"\"\n",
    "    corpus_list = []\n",
    "    for sample in hf_dataset:\n",
    "        text = (sample[\"instruction\"] or \"\") + \" \" + (sample[\"input\"] or \"\")\n",
    "        corpus_list.append(text)\n",
    "    # Combine into one big string\n",
    "    corpus = \"\\n\".join(corpus_list)\n",
    "    return corpus\n",
    "\n",
    "corpus = build_corpus_for_shrinking(llama_data_dataset)\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shrink_embeddings(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            corpus=corpus,                  # ensures relevant tokens are kept\n",
    "            keep_special_tokens=True,\n",
    "            keep_normalizer=False,\n",
    "            keep_token_order=True\n",
    "        )\n",
    "\n",
    "print(\"Tokenizer size after shrinking:\", len(tokenizer.vocab))\n",
    "\n",
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [128000, 128256, 15, 220, 22, 220, 22, 128258, 22, 220, 22, 220, 22, 128258, 15, 220, 22, 220, 22, 128259, 128257, 15, 220, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 128258, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 128258, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 128258, 22, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 128258, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 128258, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 220, 22, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 22, 128001, 128259, 128256, 19, 220, 15, 220, 19, 128258, 15, 220, 15, 220, 15, 128258, 15, 220, 19, 220, 15, 128259, 128257, 19, 220, 15, 220, 19, 220, 15, 220, 15, 220, 15, 220, 19, 220, 15, 220, 19, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 19, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 19, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 19, 220, 15, 220, 19, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 19, 220, 15, 220, 15, 220, 15, 220, 15, 128001, 128259, 128256, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 17, 128258, 17, 220, 15, 220, 17, 128259, 128257, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 17, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 17, 220, 15, 220, 17, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 17, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 17, 128258, 17, 220, 15, 220, 17, 220, 15, 220, 15, 220, 15, 220, 17, 220, 15, 220, 17, 128001, 128259, 128256, 21, 220, 21, 220, 15, 128258, 21, 220, 15, 220, 15, 128258, 15, 220, 21, 220, 21, 128259, 128257, 21, 220, 21, 220, 15, 220, 21, 220, 21, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 21, 220, 15, 220, 15, 220, 21, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 21, 220, 21, 220, 15, 220, 21, 220, 21, 220, 15, 220, 15, 220, 15, 128258, 21, 220, 21, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 21, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 21, 220, 21, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 21, 220, 21, 220, 15, 220, 21, 220, 21, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 21, 220, 15, 220, 15, 220, 21, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 21, 220, 21, 220, 15, 220, 21, 220, 21, 128001, 128259, 128256, 17, 220, 17, 220, 17, 128258, 15, 220, 15, 220, 15, 128258, 15, 220, 17, 220, 17, 128259, 128257, 17, 220, 17, 220, 17, 220, 17, 220, 17, 220, 17, 220, 17, 220, 17, 220, 17, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 17, 220, 17, 220, 15, 220, 17, 220, 17, 220, 15, 220, 17, 220, 17, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 17, 220, 17, 220, 17, 220, 17, 220, 17, 220, 17, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 220, 15, 128258, 15, 220, 15, 220, 15, 220, 15, 220, 17, 220, 17, 220, 15, 220, 17, 220, 17, 128001, 128259, 128256, 22, 220, 15, 220, 22, 128258, 22, 220, 15, 220, 22, 128258, 22, 220, 22, 220, 15, 128259, 128257, 22, 220, 15, 220, 22, 220, 15, 220, 15, 220, 15, 220, 22, 220, 15, 220, 22, 128258, 22, 220, 15, 220, 22, 220, 15, 220, 15, 220, 15, 220, 22, 220, 15, 220, 22, 128258, 22, 220, 22, 220, 15, 220, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 15, 128258, 22, 220, 15, 220, 22, 220, 15, 220, 15, 220, 15, 220, 22, 220, 15, 220, 22, 128258, 22, 220, 15, 220, 22, 220, 15, 220, 15, 220, 15, 220, 22, 220, 15, 220, 22, 128258, 22, 220, 22, 220, 15, 220, 15, 220, 15, 220, 15, 220, 22, 220, 22, 220, 15, 128258, 22, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 15, 220, 15, 220, 15, 128258, 22, 220, 15, 220, 22, 220, 22, 220, 15, 220, 22, 220, 15, 220, 15, 220, 15, 128258, 22, 220, 22, 220, 15, 220, 22, 220, 22, 220, 15, 220, 15, 220, 15, 220, 15, 128001]\n",
      "Decoded: <|begin_of_text|><I>0 7 7\n",
      "7 7 7\n",
      "0 7 7\n",
      "---\n",
      "<O>0 0 0 0 7 7 0 7 7\n",
      "0 0 0 7 7 7 7 7 7\n",
      "0 0 0 0 7 7 0 7 7\n",
      "0 7 7 0 7 7 0 7 7\n",
      "7 7 7 7 7 7 7 7 7\n",
      "0 7 7 0 7 7 0 7 7\n",
      "0 0 0 0 7 7 0 7 7\n",
      "0 0 0 7 7 7 7 7 7\n",
      "0 0 0 0 7 7 0 7 7<|end_of_text|>\n",
      "---\n",
      "<I>4 0 4\n",
      "0 0 0\n",
      "0 4 0\n",
      "---\n",
      "<O>4 0 4 0 0 0 4 0 4\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 4 0 0 0 0 0 4 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 4 0 4 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 4 0 0 0 0<|end_of_text|>\n",
      "---\n",
      "<I>0 0 0\n",
      "0 0 2\n",
      "2 0 2\n",
      "---\n",
      "<O>0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 2\n",
      "0 0 0 0 0 0 2 0 2\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 2 0 0 0 0 0 2\n",
      "2 0 2 0 0 0 2 0 2<|end_of_text|>\n",
      "---\n",
      "<I>6 6 0\n",
      "6 0 0\n",
      "0 6 6\n",
      "---\n",
      "<O>6 6 0 6 6 0 0 0 0\n",
      "6 0 0 6 0 0 0 0 0\n",
      "0 6 6 0 6 6 0 0 0\n",
      "6 6 0 0 0 0 0 0 0\n",
      "6 0 0 0 0 0 0 0 0\n",
      "0 6 6 0 0 0 0 0 0\n",
      "0 0 0 6 6 0 6 6 0\n",
      "0 0 0 6 0 0 6 0 0\n",
      "0 0 0 0 6 6 0 6 6<|end_of_text|>\n",
      "---\n",
      "<I>2 2 2\n",
      "0 0 0\n",
      "0 2 2\n",
      "---\n",
      "<O>2 2 2 2 2 2 2 2 2\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 2 2 0 2 2 0 2 2\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 2 2 2 2 2 2\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 2 2 0 2 2<|end_of_text|>\n",
      "---\n",
      "<I>7 0 7\n",
      "7 0 7\n",
      "7 7 0\n",
      "---\n",
      "<O>7 0 7 0 0 0 7 0 7\n",
      "7 0 7 0 0 0 7 0 7\n",
      "7 7 0 0 0 0 7 7 0\n",
      "7 0 7 0 0 0 7 0 7\n",
      "7 0 7 0 0 0 7 0 7\n",
      "7 7 0 0 0 0 7 7 0\n",
      "7 0 7 7 0 7 0 0 0\n",
      "7 0 7 7 0 7 0 0 0\n",
      "7 7 0 7 7 0 0 0 0<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "test_sequence = llama_data_dataset[0][\"input\"]\n",
    "\n",
    "encoded = tokenizer.encode(test_sequence)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Encoded:\", encoded)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply LoRA to the Shrunk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdelinea/anaconda3/envs/Env/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    r=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"embed_tokens\", \"lm_head\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.0,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "# Wrap the shrunk model with LoRA\n",
    "model_shrinked = get_peft_model(model, peft_config)\n",
    "\n",
    "# Make sure to unfreeze embeddings if you want to train them directly \n",
    "# (LoRA on embed_tokens will still add ranks; but if you want the base embedding \n",
    "#  weights to be trainable, do something like):\n",
    "for param in model_shrinked.get_input_embeddings().parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full architecture\n",
    "\n",
    "### Add Classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class LLMWithClassificationHead(PreTrainedModel):\n",
    "    def __init__(self, base_model, config, num_labels):\n",
    "        super().__init__(config)\n",
    "        if isinstance(base_model, LLMWithClassificationHead):\n",
    "            raise ValueError(\"base_model cannot be an instance of LLMWithClassificationHead\")\n",
    "        \n",
    "        self.base_model_1 = (base_model)\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        hidden_size = config.hidden_size\n",
    "\n",
    "        # Ensure classifier supports fp16\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_ids, output_hidden_states=True, return_dict=True, attention_mask=None, labels=None):\n",
    "        outputs = self.base_model_1(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "        last_hidden = outputs.hidden_states[-1]\n",
    "        pooled = last_hidden[:, -1, :]  # Taking the last token's hidden state\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels.float())\n",
    "\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"loss\": loss,\n",
    "            \"hidden_states\": outputs.hidden_states,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load configuration and base model\n",
    "base_config = AutoConfig.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
    "\n",
    "# Define number of labels for classification\n",
    "num_labels = 16\n",
    "\n",
    "# Instantiate the custom model\n",
    "model_classification = LLMWithClassificationHead(\n",
    "    base_model=model_shrinked,\n",
    "    config=base_config,\n",
    "    num_labels=num_labels\n",
    ").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 18015 95th percentile: 7011.749999999998\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(tokenizer.encode(example[\"input\"])) for example in llama_data_dataset]\n",
    "print(\"Max length:\", max(lengths), \"95th percentile:\", np.percentile(lengths, 95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<00:00, 642.01 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 442.74 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        max_length=7000  # Reduced from 8192 to 2048\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": examples[\"output\"]\n",
    "    }\n",
    "\n",
    "\n",
    "# Keep only the input output no instructions for now\n",
    "final_dataset = llama_data_dataset.remove_columns([\"instruction\"])\n",
    "final_dataset_testing = llama_data_dataset_testing.remove_columns([\"instruction\"])\n",
    "\n",
    "tokenized_final_dataset = final_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_final_test = final_dataset_testing.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Extract labels\n",
    "        labels = inputs.pop(\"labels\", None)\n",
    "        if labels is None:\n",
    "            raise ValueError(\"Labels are missing in inputs\")\n",
    "\n",
    "        \n",
    "        # Forward pass with additional arguments\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        \n",
    "        # Extract loss\n",
    "        loss = outputs[\"loss\"]\n",
    "        \n",
    "        # Return loss and outputs if required\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdelinea/anaconda3/envs/Env/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_751386/1697175700.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    }
   ],
   "source": [
    "# Clear cache before training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define TrainingArguments with optimizations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./JS_finetuned_model\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    learning_rate=1e-4,  # instead of 1e-4\n",
    "    per_device_train_batch_size=1,  # Reduced batch size\n",
    "    per_device_eval_batch_size=1,  # Reduced batch size\n",
    "    num_train_epochs=5,  # Increased epochs if feasible\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    gradient_accumulation_steps=4,  # Increased gradient accumulation\n",
    "    #gradient_checkpointing=True,  # Enable gradient checkpointing\n",
    "    #save_total_limit=1,\n",
    "    #save_strategy=\"epoch\",\n",
    "    #save_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"wandb\",  # Log to W&B\n",
    "    # Add any other necessary arguments\n",
    ")\n",
    "\n",
    "# Use built-in data collator with dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding='longest')\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model_classification,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_final_dataset,\n",
    "    #eval_dataset=tokenized_final_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Start Training\n",
    "#trainer.train()\n",
    "\n",
    "# Clear memory after training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#torch.save(model.state_dict(), \"./JS_finetuned_model/pytorch_model.bin\")\n",
    "#model.config.save_pretrained(\"./JS_finetuned_model\")\n",
    "#tokenizer.save_pretrained(\"./JS_finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 12693.37 MB\n",
      "Memory cached: 12742.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Memory cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdelinea/anaconda3/envs/Env/lib/python3.10/site-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "/tmp/ipykernel_751386/3683129824.py:7: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([128261, 3072])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 128261])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([64, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([128261, 64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.Tensor'>, Size: 80 bytes, Shape: torch.Size([64])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([16, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([16])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([1024, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([8192, 3072])\n",
      "Type: <class 'torch.nn.parameter.Parameter'>, Size: 80 bytes, Shape: torch.Size([3072, 8192])\n"
     ]
    }
   ],
   "source": [
    "# Force garbage collection to remove unreferenced objects\n",
    "gc.collect()\n",
    "\n",
    "# List all objects and their sizes\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(f\"Type: {type(obj)}, Size: {sys.getsizeof(obj)} bytes, Shape: {obj.size()}\")\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  12693 MiB |  12693 MiB |  12693 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  12693 MiB |  12693 MiB |  12693 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  12691 MiB |  12691 MiB |  12691 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  12742 MiB |  12742 MiB |  12742 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  49797 KiB |  67690 KiB | 549632 KiB | 499835 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     681    |     681    |     681    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     681    |     681    |     681    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     326    |     326    |     326    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     100    |     101    |     148    |      48    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(torch.cuda.memory_summary(device=0, abbreviated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjean-sebastien-delineau\u001b[0m (\u001b[33mdrykx\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jdelinea/ARC-AGI/BARC/wandb/run-20250103_111736-lgy08fwa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/drykx/huggingface/runs/lgy08fwa' target=\"_blank\">./JS_finetuned_model</a></strong> to <a href='https://wandb.ai/drykx/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/drykx/huggingface' target=\"_blank\">https://wandb.ai/drykx/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/drykx/huggingface/runs/lgy08fwa' target=\"_blank\">https://wandb.ai/drykx/huggingface/runs/lgy08fwa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics: [{'test_loss': 0.684650182723999, 'test_model_preparation_time': 0.0138, 'test_runtime': 15.5665, 'test_samples_per_second': 0.642, 'test_steps_per_second': 0.642}, {'test_loss': 0.6784305572509766, 'test_model_preparation_time': 0.0138, 'test_runtime': 15.4493, 'test_samples_per_second': 0.647, 'test_steps_per_second': 0.647}, {'test_loss': 0.6686240434646606, 'test_model_preparation_time': 0.0138, 'test_runtime': 15.6992, 'test_samples_per_second': 0.637, 'test_steps_per_second': 0.637}, {'test_loss': 0.653450608253479, 'test_model_preparation_time': 0.0138, 'test_runtime': 16.197, 'test_samples_per_second': 0.617, 'test_steps_per_second': 0.617}, {'test_loss': 0.6514352560043335, 'test_model_preparation_time': 0.0138, 'test_runtime': 16.8, 'test_samples_per_second': 0.595, 'test_steps_per_second': 0.595}]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear memory after training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Batch size\n",
    "batch_size = 10\n",
    "num_batches = len(tokenized_final_test) // batch_size  # Number of batches\n",
    "\n",
    "# Run predictions on the evaluation dataset in fixed batches\n",
    "predictions = []\n",
    "for batch_idx in range(num_batches):\n",
    "    # Slice the dataset for the current batch\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    batch = tokenized_final_dataset.select(range(start_idx, end_idx))\n",
    "    \n",
    "    # Run prediction for the batch\n",
    "    prediction = trainer.predict(batch)\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    # Clear memory after each batch\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Combine batch predictions\n",
    "logits = [pred.predictions for pred in predictions]  # Model outputs\n",
    "true_labels = [pred.label_ids for pred in predictions]  # True labels\n",
    "metrics = [pred.metrics for pred in predictions]  # Metrics\n",
    "\n",
    "# Print combined metrics\n",
    "# (Optional: Aggregate metrics if necessary, e.g., averaging)\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Clear memory after evaluation\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0\n",
      "Predicted Labels: ['quantitative', 'motion']\n",
      "True Labels: ['spatial-Ordinal', 'replication']\n",
      "Example 1\n",
      "Predicted Labels: ['motion', 'size']\n",
      "True Labels: ['centroid']\n",
      "Example 2\n",
      "Predicted Labels: ['centroid', 'quantitative']\n",
      "True Labels: ['replication']\n",
      "Example 3\n",
      "Predicted Labels: ['size', 'quantitative']\n",
      "True Labels: ['motion']\n",
      "Example 4\n",
      "Predicted Labels: ['closure', 'size']\n",
      "True Labels: ['replication', 'continuity']\n",
      "Example 5\n",
      "Predicted Labels: ['closure', 'quantitative']\n",
      "True Labels: ['categorical']\n",
      "Example 6\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['replication']\n",
      "Example 7\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['categorical', 'motion']\n",
      "Example 8\n",
      "Predicted Labels: ['motion', 'size']\n",
      "True Labels: ['topological']\n",
      "Example 9\n",
      "Predicted Labels: ['size', 'quantitative']\n",
      "True Labels: ['size']\n",
      "Example 10\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['similarity']\n",
      "Example 11\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['replication']\n",
      "Example 12\n",
      "Predicted Labels: ['quantitative', 'motion']\n",
      "True Labels: ['continuity']\n",
      "Example 13\n",
      "Predicted Labels: ['size', 'quantitative']\n",
      "True Labels: ['similarity']\n",
      "Example 14\n",
      "Predicted Labels: ['size', 'quantitative']\n",
      "True Labels: ['replication']\n",
      "Example 15\n",
      "Predicted Labels: ['quantitative', 'motion']\n",
      "True Labels: ['symmetry']\n",
      "Example 16\n",
      "Predicted Labels: ['containment', 'size']\n",
      "True Labels: ['symmetry', 'replication']\n",
      "Example 17\n",
      "Predicted Labels: ['size', 'quantitative']\n",
      "True Labels: ['similarity']\n",
      "Example 18\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['replication']\n",
      "Example 19\n",
      "Predicted Labels: ['size', 'motion']\n",
      "True Labels: ['symmetry']\n",
      "Example 20\n",
      "Predicted Labels: ['centroid', 'size']\n",
      "True Labels: ['quantitative']\n",
      "Example 21\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['depth', 'motion']\n",
      "Example 22\n",
      "Predicted Labels: ['motion', 'size']\n",
      "True Labels: ['similarity', 'topological']\n",
      "Example 23\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['depth', 'continuity']\n",
      "Example 24\n",
      "Predicted Labels: ['size', 'motion']\n",
      "True Labels: ['motion']\n",
      "Example 25\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['categorical']\n",
      "Example 26\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['symmetry']\n",
      "Example 27\n",
      "Predicted Labels: ['motion', 'size']\n",
      "True Labels: ['continuity']\n",
      "Example 28\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['figure-Ground']\n",
      "Example 29\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['spatial-Ordinal']\n",
      "Example 30\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['figure-Ground']\n",
      "Example 31\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['motion']\n",
      "Example 32\n",
      "Predicted Labels: ['motion', 'size']\n",
      "True Labels: ['replication']\n",
      "Example 33\n",
      "Predicted Labels: ['size', 'quantitative']\n",
      "True Labels: ['continuity']\n",
      "Example 34\n",
      "Predicted Labels: ['size', 'motion']\n",
      "True Labels: ['continuity']\n",
      "Example 35\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['figure-Ground']\n",
      "Example 36\n",
      "Predicted Labels: ['motion', 'size']\n",
      "True Labels: ['continuity', 'topological']\n",
      "Example 37\n",
      "Predicted Labels: ['closure', 'quantitative']\n",
      "True Labels: ['quantitative']\n",
      "Example 38\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['symmetry', 'similarity']\n",
      "Example 39\n",
      "Predicted Labels: ['size', 'motion']\n",
      "True Labels: ['spatial-Ordinal']\n",
      "Example 40\n",
      "Predicted Labels: ['size', 'motion']\n",
      "True Labels: ['closure']\n",
      "Example 41\n",
      "Predicted Labels: ['motion', 'size']\n",
      "True Labels: ['topological', 'motion']\n",
      "Example 42\n",
      "Predicted Labels: ['size', 'quantitative']\n",
      "True Labels: ['replication']\n",
      "Example 43\n",
      "Predicted Labels: ['quantitative', 'size']\n",
      "True Labels: ['centroid', 'motion']\n",
      "Example 44\n",
      "Predicted Labels: ['size', 'motion']\n",
      "True Labels: ['categorical']\n",
      "Example 45\n",
      "Predicted Labels: ['closure', 'quantitative']\n",
      "True Labels: ['depth', 'topological']\n",
      "Example 46\n",
      "Predicted Labels: ['motion', 'quantitative']\n",
      "True Labels: ['depth', 'continuity']\n",
      "Example 47\n",
      "Predicted Labels: ['closure', 'quantitative']\n",
      "True Labels: ['topological']\n",
      "Example 48\n",
      "Predicted Labels: ['size', 'motion']\n",
      "True Labels: ['size']\n",
      "Example 49\n",
      "Predicted Labels: ['closure', 'motion']\n",
      "True Labels: ['spatial-Ordinal', 'closure']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, precision_score, recall_score, f1_score\n",
    "\n",
    "# Parameters\n",
    "threshold = 0.1\n",
    "\n",
    "# Placeholder for empirical labels\n",
    "emp_labels = []\n",
    "\n",
    "# Process logits\n",
    "for j, batch_logits in enumerate(logits):\n",
    "    exp_scores = np.exp(batch_logits[0])  # Vectorized exponentiation\n",
    "    probabilities = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # Softmax\n",
    "    pred_label_indices = np.argsort(probabilities, axis=1)[:, -2:]  # Top 2 indices\n",
    "    batch_labels = (probabilities > threshold).astype(int)  # Thresholding\n",
    "    emp_labels.extend(batch_labels.tolist())  # Append predictions\n",
    "    \n",
    "    # Logging predictions\n",
    "    for i, indices in enumerate(pred_label_indices):\n",
    "        example_id = i + 10 * j\n",
    "        print(f\"Example {example_id}\")\n",
    "        print(\"Predicted Labels:\", [label_list[idx] for idx in indices])\n",
    "        true_indices = [idx for idx, val in enumerate(true_labels[j][i]) if val == 1]\n",
    "        print(\"True Labels:\", [label_list[idx] for idx in true_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Ratio: 0.0\n",
      "Hamming Loss: 0.2425\n",
      "Precision: 0.06966666666666667\n",
      "Recall: 0.17\n",
      "F1 Measure: 0.09676190476190476\n"
     ]
    }
   ],
   "source": [
    "# Convert true labels to a single array\n",
    "true_labels_list = np.vstack(true_labels)\n",
    "\n",
    "# Metrics computation\n",
    "y_pred = np.array(emp_labels)\n",
    "y_true = true_labels_list\n",
    "\n",
    "print('Exact Match Ratio:', accuracy_score(y_true, y_pred))\n",
    "print('Hamming Loss:', hamming_loss(y_true, y_pred))\n",
    "print('Precision:', precision_score(y_true, y_pred, average='samples'))\n",
    "print('Recall:', recall_score(y_true, y_pred, average='samples'))\n",
    "print('F1 Measure:', f1_score(y_true, y_pred, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
