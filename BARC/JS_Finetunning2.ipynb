{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Packages\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import importlib.util\n",
    "from typing import *\n",
    "from tqdm import tqdm \n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "from JS_Architects import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We will use Architects model\n",
    "\n",
    "1) Implement Custom pipeline, no prompting just prediction with shrekking of the embedding \n",
    "\n",
    "2) Automated Forsequence Classification\n",
    "    1) No prompting\n",
    "    2) Prompt: \"Classify with labels encode in binary\"\n",
    "    3) Prompt: \"Clasify with list label: [\"depth\",...]\"\n",
    "    4) Prompt \"Classify with list label: [\"depth\",...]. Depth represents..., Containment represents....\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Pipeline \n",
    "\n",
    "## 1. Prepare Data\n",
    "\n",
    "### Load \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"perceptions_training.json\", \"r\") as f:\n",
    "    dic_training = json.load(f)\n",
    "\n",
    "with open(\"perceptions_testing.json\", \"r\") as f:\n",
    "    dic_testing = json.load(f)\n",
    "\n",
    "label_list = [\n",
    "    \"containment\",\n",
    "    \"depth\",\n",
    "    \"symmetry\",\n",
    "    \"categorical\",\n",
    "    \"spatial-Orientation\",\n",
    "    \"spatial-Ordinal\",\n",
    "    \"similarity\",\n",
    "    \"quantitative\",\n",
    "    \"replication\",\n",
    "    \"figure-Ground\",\n",
    "    \"continuity\",\n",
    "    \"size\",\n",
    "    \"closure\",\n",
    "    \"centroid\",\n",
    "    \"topological\",\n",
    "    \"motion\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def prepare_data_for_multilabel_classification(\n",
    "    dic_training,\n",
    "    instruction,\n",
    "    label_list,\n",
    "    inp_prefix=\"<I>\",\n",
    "    out_prefix=\"<O>\",\n",
    "    arr_sep=\"\\n\",\n",
    "    exa_sep=\"\\n---\\n\",\n",
    "    eos_token=\"<EOS>\"\n",
    "):\n",
    "    llama_data = []\n",
    "\n",
    "    # Create a mapping from label to index\n",
    "    label_to_index = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    for entry_id, content in dic_training.items():\n",
    "        # Extract perceptions (labels) and encode them as a binary vector\n",
    "        perceptions = content.get(\"perceptions\", [])\n",
    "        label_vector = labels_to_binary(label_list, perceptions)\n",
    "\n",
    "        # Combine train and test examples\n",
    "        examples = content.get(\"example\", {}).get(\"train\", []) + content.get(\"example\", {}).get(\"test\", [])\n",
    "\n",
    "        # Format examples into a single input string\n",
    "        formatted_examples = []\n",
    "        for example in examples:\n",
    "            input_data = f\"{inp_prefix}{format_array(example['input'], arr_sep)}\"\n",
    "            output_data = f\"{out_prefix}{format_array(example['output'], arr_sep)}{eos_token}\"\n",
    "            formatted_examples.append(f\"{input_data}{exa_sep}{output_data}\")\n",
    "\n",
    "        # Combine all examples into one input text\n",
    "        combined_text = exa_sep.join(formatted_examples)\n",
    "\n",
    "        # Add the structured data for fine-tuning\n",
    "        llama_data.append({\n",
    "            \"instruction\": f\"{instruction}\",\n",
    "            #\"instruction\": f\"{instruction}: {', '.join(label_list)}.\",\n",
    "            \"input\": combined_text,\n",
    "            \"output\": label_vector,  # Multi-label as binary vector\n",
    "        })\n",
    "\n",
    "    return llama_data\n",
    "\n",
    "def format_array(array, arr_sep=\"\\n\"):\n",
    "    \"\"\"\n",
    "    Helper function to format a 2D array into a string with row-wise separation.\n",
    "    \"\"\"\n",
    "    return arr_sep.join([\" \".join(map(str, row)) for row in array])\n",
    "\n",
    "def labels_to_binary(label_list, input_labels):\n",
    "    \"\"\"\n",
    "    Convert perceptions into a binary vector based on the label list.\n",
    "    Handles both single strings and lists of strings for input_labels.\n",
    "    \"\"\"\n",
    "    # Ensure input_labels is treated as a list\n",
    "    if isinstance(input_labels, str):\n",
    "        input_labels = [input_labels]\n",
    "    \n",
    "    # Create a set of lowercase input labels\n",
    "    input_set = set(label.lower() for label in input_labels)\n",
    "    \n",
    "    # Generate the binary vector\n",
    "    return [1 if label.lower() in input_set else 0 for label in label_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '',\n",
       " 'input': '<I>0 7 7\\n7 7 7\\n0 7 7\\n---\\n<O>0 0 0 0 7 7 0 7 7\\n0 0 0 7 7 7 7 7 7\\n0 0 0 0 7 7 0 7 7\\n0 7 7 0 7 7 0 7 7\\n7 7 7 7 7 7 7 7 7\\n0 7 7 0 7 7 0 7 7\\n0 0 0 0 7 7 0 7 7\\n0 0 0 7 7 7 7 7 7\\n0 0 0 0 7 7 0 7 7<EOS>\\n---\\n<I>4 0 4\\n0 0 0\\n0 4 0\\n---\\n<O>4 0 4 0 0 0 4 0 4\\n0 0 0 0 0 0 0 0 0\\n0 4 0 0 0 0 0 4 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 4 0 4 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 4 0 0 0 0<EOS>\\n---\\n<I>0 0 0\\n0 0 2\\n2 0 2\\n---\\n<O>0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 2\\n0 0 0 0 0 0 2 0 2\\n0 0 0 0 0 0 0 0 0\\n0 0 2 0 0 0 0 0 2\\n2 0 2 0 0 0 2 0 2<EOS>\\n---\\n<I>6 6 0\\n6 0 0\\n0 6 6\\n---\\n<O>6 6 0 6 6 0 0 0 0\\n6 0 0 6 0 0 0 0 0\\n0 6 6 0 6 6 0 0 0\\n6 6 0 0 0 0 0 0 0\\n6 0 0 0 0 0 0 0 0\\n0 6 6 0 0 0 0 0 0\\n0 0 0 6 6 0 6 6 0\\n0 0 0 6 0 0 6 0 0\\n0 0 0 0 6 6 0 6 6<EOS>\\n---\\n<I>2 2 2\\n0 0 0\\n0 2 2\\n---\\n<O>2 2 2 2 2 2 2 2 2\\n0 0 0 0 0 0 0 0 0\\n0 2 2 0 2 2 0 2 2\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 2 2 2 2 2 2\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 2 2 0 2 2<EOS>\\n---\\n<I>7 0 7\\n7 0 7\\n7 7 0\\n---\\n<O>7 0 7 0 0 0 7 0 7\\n7 0 7 0 0 0 7 0 7\\n7 7 0 0 0 0 7 7 0\\n7 0 7 0 0 0 7 0 7\\n7 0 7 0 0 0 7 0 7\\n7 7 0 0 0 0 7 7 0\\n7 0 7 7 0 7 0 0 0\\n7 0 7 7 0 7 0 0 0\\n7 7 0 7 7 0 0 0 0<EOS>',\n",
       " 'output': [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction0 = \"\"\n",
    "instruction1 = \"Classify the relationship between the input and output sequences based on perceptions\"\n",
    "\n",
    "# List\n",
    "llama_data = prepare_data_for_multilabel_classification(dic_training,instruction0,label_list)\n",
    "\n",
    "# Dict\n",
    "llama_data_dict = {\n",
    "    \"instruction\": [item[\"instruction\"] for item in llama_data],\n",
    "    \"input\": [item[\"input\"] for item in llama_data],\n",
    "    \"output\": [item[\"output\"] for item in llama_data],\n",
    "}\n",
    "\n",
    "# Dataset\n",
    "llama_data_dataset = Dataset.from_dict(llama_data_dict)\n",
    "\n",
    "llama_data_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '',\n",
       " 'input': '<I>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0\\n0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0\\n0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1\\n0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1\\n0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0\\n0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0\\n0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0\\n0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\\n0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\\n0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\\n0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0\\n0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 3 1 1 0 0 0 1 1 1 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0\\n---\\n<O>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 2 2 1 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 1 2 2 2 1 0 0 0 0 0 1 2 2 1 0 0 0 0\\n0 0 0 0 0 1 2 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 2 1 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 1 2 2 2 1 0 0 0 0 0 1 1 1 1 0 0 0 0\\n0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 2 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1\\n0 0 0 0 0 1 1 1 0 0 1 2 2 2 2 2 2 2 1 1 1 1 2 2 1 1 1 1 2 1\\n0 0 0 0 0 1 2 1 1 1 1 2 2 2 2 2 2 2 1 0 0 1 2 2 1 0 0 1 1 1\\n0 0 0 0 0 1 1 1 0 0 1 2 2 2 2 2 2 2 1 0 0 1 1 1 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 1 1 0 0 0 1 3 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 3 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 2 2 1 0 1 1 1 0 1 1 1 0 0 0 0\\n0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 2 2 1 0 1 3 1 1 1 3 1 0 0 0 0\\n0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0\\n0 0 1 1 1 0 0 1 3 3 3 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\\n0 0 1 3 1 1 1 1 3 3 3 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\\n0 0 1 1 1 0 0 1 3 3 3 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\\n0 0 0 0 0 0 0 1 3 3 3 1 1 1 1 3 3 3 3 1 0 0 0 1 1 1 0 0 0 0\\n0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 3 3 3 3 1 1 1 1 1 3 1 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 3 3 1 0 0 0 1 3 1 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0<EOS>\\n---\\n<I>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 1 3 1 1 0 0 0 0 0 0 0 0 1 1 4 1 0 0\\n0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0\\n0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0\\n0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0\\n0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0\\n0 0 0 0 0 1 1 2 1 1 1 1 1 1 0 0 0 0 0 0\\n1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0\\n1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\\n1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n---\\n<O>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 1 3 3 1 0 0 0 0 0 0 0 0 1 4 4 1 0 0\\n0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 4 4 1 0 0\\n0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0\\n0 0 1 3 3 3 3 1 0 1 1 1 0 0 0 1 1 1 0 0\\n0 0 1 3 3 3 3 1 1 1 3 1 0 0 0 1 4 1 0 0\\n0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0\\n0 0 0 0 0 1 2 2 1 1 1 1 2 1 0 0 0 0 0 0\\n1 1 1 0 0 1 2 2 1 0 0 1 1 1 0 0 0 0 0 0\\n1 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n1 2 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\\n1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 1 2 1 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0<EOS>\\n---\\n<I>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0\\n0 0 0 1 4 1 1 1 1 1 1 1 1 0 0 1 1 1\\n0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1\\n0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1\\n0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0\\n0 0 0 1 1 1 1 0 0 1 3 1 1 1 1 1 0 0\\n0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0\\n0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0\\n0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0\\n0 0 1 1 6 1 1 1 1 1 1 1 1 1 1 1 0 0\\n0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0\\n---\\n<O>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0\\n0 0 0 1 4 4 1 1 1 1 4 4 1 0 0 1 1 1\\n0 0 0 1 1 1 1 0 0 1 4 4 1 1 1 1 4 1\\n0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1\\n0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0\\n0 0 0 1 4 4 1 0 0 1 3 1 1 1 3 1 0 0\\n0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 0 0 0 0 0 1 6 1 0 0\\n0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0\\n0 0 1 1 1 1 0 0 1 6 6 1 0 0 1 0 0 0\\n0 0 1 6 6 1 0 0 1 6 6 1 0 1 1 1 0 0\\n0 0 1 6 6 1 1 1 1 6 6 1 1 1 6 1 0 0\\n0 0 1 1 1 1 0 0 1 6 6 1 0 1 1 1 0 0\\n0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0<EOS>\\n---\\n<I>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0\\n0 0 1 1 1 1 0 0 1 1 4 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0\\n0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\\n0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0\\n0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0\\n0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0\\n0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0\\n0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0\\n0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0\\n0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 8 1 1 1 0 1 1 1 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\\n0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\\n0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 6 1 0\\n0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\\n0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\\n0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\\n0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0\\n0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0\\n0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0\\n0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\\n0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0\\n---\\n<O>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0\\n0 0 1 1 1 1 0 0 1 4 4 4 1 0 0 1 1 1 1 1 1 0 0 1 4 4 4 4 1 0\\n0 0 1 4 4 1 1 1 1 4 4 4 1 1 1 1 4 4 4 4 1 1 1 1 4 4 4 4 1 0\\n0 0 1 4 4 1 0 0 1 4 4 4 1 0 0 1 4 4 4 4 1 0 0 1 4 4 4 4 1 0\\n0 0 1 1 1 1 0 0 1 4 4 4 1 0 0 1 1 1 1 1 1 0 0 1 4 4 4 4 1 0\\n0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0\\n0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0\\n0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 4 4 1 0 0 0 0 1 1 1 1 0 0\\n0 0 0 0 1 4 4 1 1 1 4 1 0 0 0 0 1 1 1 1 0 0 0 0 1 4 4 1 0 0\\n0 0 0 0 1 1 1 1 0 1 4 1 0 0 0 0 0 0 0 0 0 0 0 0 1 4 4 1 0 0\\n0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\\n0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 1 4 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 8 8 8 1 0 1 1 1 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 8 8 8 1 1 1 8 8 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 8 1 0 0 0 1 8 8 8 1 0 1 1 1 1 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\\n0 1 1 1 0 1 1 1 0 1 8 8 8 8 8 8 8 8 8 8 1 0 0 0 0 1 1 1 1 0\\n0 1 8 1 1 1 8 1 0 1 8 8 8 8 8 8 8 8 8 8 1 0 0 0 0 1 6 6 1 0\\n0 1 1 1 0 1 8 1 1 1 8 8 8 8 8 8 8 8 8 8 1 0 0 0 0 1 6 6 1 0\\n0 0 0 0 0 1 1 1 0 1 8 8 8 8 8 8 8 8 8 8 1 0 0 0 0 1 6 6 1 0\\n0 0 0 0 0 0 0 0 0 1 8 8 8 8 8 8 8 8 8 8 1 0 0 0 0 1 1 1 1 0\\n0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0\\n0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0\\n0 0 1 6 6 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 6 6 1 0\\n0 0 1 6 6 1 1 1 1 6 6 1 1 1 1 1 6 6 1 1 1 1 1 1 1 1 6 6 1 0\\n0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0<EOS>',\n",
       " 'output': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_data_list_testing = prepare_data_for_multilabel_classification(dic_testing,instruction0, label_list)\n",
    "\n",
    "# Restructure llama_data\n",
    "llama_data_dict_testing = {\n",
    "    \"instruction\": [item[\"instruction\"] for item in llama_data_list_testing],\n",
    "    \"input\": [item[\"input\"] for item in llama_data_list_testing],\n",
    "    \"output\": [item[\"output\"] for item in llama_data_list_testing],\n",
    "}\n",
    "\n",
    "llama_data_dataset_testing = Dataset.from_dict(llama_data_dict_testing)\n",
    "llama_data_dataset_testing[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nvidia/Mistral-NeMo-Minitron-8B-Base\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"nvidia/Mistral-NeMo-Minitron-8B-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial length vocabulary: 131072\n"
     ]
    }
   ],
   "source": [
    "print(f\"The initial length vocabulary: {len(tokenizer.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Shrink and FT the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376186"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_corpus_for_shrinking(hf_dataset):\n",
    "    \"\"\"\n",
    "    Concatenate the 'input' + 'instruction' from the dataset\n",
    "    to ensure all relevant tokens appear.\n",
    "    \"\"\"\n",
    "    corpus_list = []\n",
    "    for sample in hf_dataset:\n",
    "        text = (sample[\"instruction\"] or \"\") + \" \" + (sample[\"input\"] or \"\")\n",
    "        corpus_list.append(text)\n",
    "    # Combine into one big string\n",
    "    corpus = \"\\n\".join(corpus_list)\n",
    "    return corpus\n",
    "\n",
    "corpus = build_corpus_for_shrinking(llama_data_dataset)\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer size after shrinking: 32\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, _ = prepare_model(\n",
    "        model=model,        # Path or HF ID, e.g. \"llama-7b-hf\"\n",
    "        mode=\"transformers\",          # or another supported mode\n",
    "        tokenizer=tokenizer,               # let prepare_model create it or pass your own\n",
    "        shrink_embedding=False,       # We'll handle shrinking below\n",
    "        #device_map=device_map,\n",
    "        # Additional kwargs if needed\n",
    "        #**tokenizer_kwargs\n",
    "    )\n",
    "\n",
    "shrink_embeddings(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            corpus=corpus,                  # ensures relevant tokens are kept\n",
    "            keep_special_tokens=True,\n",
    "            keep_normalizer=False,\n",
    "            keep_token_order=True\n",
    "        )\n",
    "\n",
    "print(\"Tokenizer size after shrinking:\", len(tokenizer.vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we shrinked the embedding we will fastly FT the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-39): 40 x MistralDecoderLayer(\n",
       "            (self_attn): MistralSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11520, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11520, bias=False)\n",
       "              (down_proj): Linear(in_features=11520, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "peft_configs = [\n",
    "    {\n",
    "        \"r\": 32,\n",
    "        \"lora_alpha\": 64,\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "        \"lora_dropout\": 0.1,\n",
    "        \"bias\": \"none\",\n",
    "        \"task_type\": \"CAUSAL_LM\"\n",
    "    }\n",
    "]\n",
    "\n",
    "model_shrinked = get_peft_model(model, LoraConfig(**peft_configs[0]))\n",
    "\n",
    "model_shrinked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Shrink embedding...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m peft_configs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     }\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m model, tokenizer, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Path or HF ID, e.g. \"llama-7b-hf\"\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or another supported mode\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# let prepare_model create it or pass your own\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshrink_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# We'll handle shrinking below\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdequantize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpeft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpeft_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#device_map=device_map,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional kwargs if needed\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#**tokenizer_kwargs\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ARC-AGI/BARC/JS_Architects.py:209\u001b[0m, in \u001b[0;36mprepare_model\u001b[0;34m(model, mode, tokenizer, formatter, shrink_embedding, dequantize, peft, local_files_only, add_special_tokens, set_pad_token, keep_tokens, keep_normalizer, peft_trainable, device_map, tf_grad_cp, tf_use_fa2, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*** Shrink embedding...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    208\u001b[0m     embedding_size_before_shrink \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[0;32m--> 209\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m shrink_embeddings(model, tokenizer, \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_corpus\u001b[49m(), keep_tokens\u001b[38;5;241m=\u001b[39mkeep_tokens, keep_normalizer\u001b[38;5;241m=\u001b[39mkeep_normalizer)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*** -> Reduced embedding size from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_size_before_shrink\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m words.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dequantize:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_corpus'"
     ]
    }
   ],
   "source": [
    "peft_configs = [\n",
    "    {\n",
    "        \"r\": 32,\n",
    "        \"lora_alpha\": 64,\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "        \"lora_dropout\": 0.1,\n",
    "        \"bias\": \"none\",\n",
    "        \"task_type\": \"CAUSAL_LM\"\n",
    "    }\n",
    "]\n",
    "\n",
    "model, tokenizer, _ = prepare_model(\n",
    "        model=model,        # Path or HF ID, e.g. \"llama-7b-hf\"\n",
    "        mode=\"transformers\",          # or another supported mode\n",
    "        formatter= None,\n",
    "        tokenizer=tokenizer,               # let prepare_model create it or pass your own\n",
    "        shrink_embedding=True,       # We'll handle shrinking below\n",
    "        dequantize= False,\n",
    "        peft= peft_configs,\n",
    "        #device_map=device_map,\n",
    "        # Additional kwargs if needed\n",
    "        #**tokenizer_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the model with a classification head\n",
    "class LLMWithClassificationHead(nn.Module):\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.num_labels = num_labels\n",
    "        hidden_size = base_model.config.hidden_size\n",
    "\n",
    "        # A linear head for classification with num_labels outputs\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        \"\"\"\n",
    "        input_ids: (batch_size, seq_len)\n",
    "        labels:    (batch_size, num_labels), 0/1 multi-label\n",
    "        \"\"\"\n",
    "        # 1) Forward pass through LLaMA in \"causal LM\" mode\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        # 2) Extract the last hidden state: (batch_size, seq_len, hidden_size)\n",
    "        last_hidden = outputs.hidden_states[-1]\n",
    "\n",
    "        # 3) We'll use the hidden state at the last token as the \"pooled\" representation\n",
    "        pooled = last_hidden[:, -1, :]  # (batch_size, hidden_size)\n",
    "\n",
    "        # 4) Classification head to produce (batch_size, num_labels)\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        # 5) If we have labels, compute BCE with logits (multi-label classification)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # shape of labels should be (batch_size, num_labels)\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels.float())\n",
    "\n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'loss': loss,\n",
    "            'hidden_states': outputs.hidden_states,\n",
    "            'attentions': outputs.attentions if hasattr(outputs, 'attentions') else None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMWithClassificationHead(\n",
       "  (base_model): MistralForCausalLM(\n",
       "    (model): MistralModel(\n",
       "      (embed_tokens): Embedding(32, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-39): 40 x MistralDecoderLayer(\n",
       "          (self_attn): MistralSdpaAttention(\n",
       "            (q_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): MistralRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): MistralMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11520, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11520, bias=False)\n",
       "            (down_proj): Linear(in_features=11520, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32, bias=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=4096, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate your custom model\n",
    "num_labels = 16\n",
    "model_Classification = LLMWithClassificationHead(\n",
    "    base_model=model,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "model_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Extract labels from inputs\n",
    "        labels = inputs.pop(\"labels\")\n",
    "\n",
    "        # Get logits from the model\n",
    "        logits = model(**inputs)\n",
    "\n",
    "        # Define Binary Cross-Entropy Loss with logits\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, logits) if return_outputs else loss\n",
    "\n",
    "def tokenize_function(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"input\"],\n",
    "        #padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=8192,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": tokenized[\"input_ids\"].squeeze().tolist(),\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"].squeeze().tolist(),\n",
    "        \"labels\": torch.tensor(example[\"output\"], dtype=torch.float32).tolist()  # Ensure labels are floats\n",
    "    }\n",
    "\n",
    "class DataCollatorWithLabels:\n",
    "    def __call__(self, features):\n",
    "        input_ids = torch.stack([torch.tensor(f[\"input_ids\"]) for f in features])\n",
    "        attention_mask = torch.stack([torch.tensor(f[\"attention_mask\"]) for f in features])\n",
    "        labels = torch.stack([torch.tensor(f[\"labels\"], dtype=torch.float32) for f in features])  # Stack labels\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdelinea/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/training_args.py:1539: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/150 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:763\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 763\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:725\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 725\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 1134 at dim 1 (got 4598)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 28\u001b[0m\n\u001b[1;32m      4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Evaluate periodically\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     ddp_find_unused_parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Apply tokenization\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mllama_data_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m tokenized_dataset_testing \u001b[38;5;241m=\u001b[39m llama_data_dataset_testing\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorWithLabels()\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/datasets/arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3055\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3056\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3057\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/datasets/arrow_dataset.py:3458\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3454\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3455\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3456\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3458\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3462\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3467\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/datasets/arrow_dataset.py:3320\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3319\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3320\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3322\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3323\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3324\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[71], line 17\u001b[0m, in \u001b[0;36mtokenize_function\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(example):\n\u001b[0;32m---> 17\u001b[0m     tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#padding=\"max_length\",\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Ensure labels are floats\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2986\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2985\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2986\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3068\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3069\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3070\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3071\u001b[0m         )\n\u001b[1;32m   3072\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3075\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3077\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3078\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3079\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3094\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3095\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3096\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3114\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3269\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3260\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3261\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3262\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3266\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3267\u001b[0m )\n\u001b[0;32m-> 3269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3271\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3286\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:578\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:228\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    224\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BarcHandbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:779\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    775\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    776\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    777\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    778\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    780\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    781\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    782\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    783\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    784\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "# Instantiate your custom model\n",
    "model_Classification = LLMWithClassificationHead(base_model=model, num_labels=16)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_model\",\n",
    "    evaluation_strategy=\"steps\",  # Evaluate periodically\n",
    "    eval_steps=500,              # Evaluate every 500 steps\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=1,  # Reduced\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"tensorboard\",\n",
    "    fp16=True,                    # Mixed-precision\n",
    "    push_to_hub=False,\n",
    "    ddp_find_unused_parameters=False,\n",
    ")\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = llama_data_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset_testing = llama_data_dataset_testing.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define trainer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_Classification,\n\u001b[1;32m      4\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m----> 5\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtokenized_dataset\u001b[49m,\n\u001b[1;32m      6\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset_testing,\n\u001b[1;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m      8\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Define trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model_Classification,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset_testing,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Training loop\n",
    "model_name = \"<path_to_base_model>\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = LLMWithClassificationHead(model_name, num_labels=16).to(\"cuda\")\n",
    "\n",
    "train_data = [{\"input\": \"...\", \"label\": [0, 1, 0, 0]}, {\"input\": \"...\", \"label\": [1, 0, 0, 0]}]\n",
    "train_dataset = ClassificationDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        labels = batch[\"labels\"].to(\"cuda\")\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, labels=labels)\n",
    "        loss = outputs[\"loss\"]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BarcHandbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
