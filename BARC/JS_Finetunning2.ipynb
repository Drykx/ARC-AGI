{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Packages\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import importlib.util\n",
    "from typing import *\n",
    "from tqdm import tqdm \n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "from JS_Architects import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We will use Architects model\n",
    "\n",
    "1) Implement Custom pipeline, no prompting just prediction with shrekking of the embedding \n",
    "\n",
    "2) Automated Forsequence Classification\n",
    "    1) No prompting\n",
    "    2) Prompt: \"Classify with labels encode in binary\"\n",
    "    3) Prompt: \"Clasify with list label: [\"depth\",...]\"\n",
    "    4) Prompt \"Classify with list label: [\"depth\",...]. Depth represents..., Containment represents....\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Pipeline \n",
    "\n",
    "## 1. Preparation\n",
    "\n",
    "### Load \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"perceptions_training.json\", \"r\") as f:\n",
    "    dic_training = json.load(f)\n",
    "\n",
    "with open(\"perceptions_testing.json\", \"r\") as f:\n",
    "    dic_testing = json.load(f)\n",
    "\n",
    "label_list = [\n",
    "    \"containment\",\n",
    "    \"depth\",\n",
    "    \"symmetry\",\n",
    "    \"categorical\",\n",
    "    \"spatial-Orientation\",\n",
    "    \"spatial-Ordinal\",\n",
    "    \"similarity\",\n",
    "    \"quantitative\",\n",
    "    \"replication\",\n",
    "    \"figure-Ground\",\n",
    "    \"continuity\",\n",
    "    \"size\",\n",
    "    \"closure\",\n",
    "    \"centroid\",\n",
    "    \"topological\",\n",
    "    \"motion\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def prepare_data_for_multilabel_classification(\n",
    "    dic_training,\n",
    "    instruction,\n",
    "    label_list,\n",
    "    inp_prefix=\"I\",\n",
    "    out_prefix=\"O\",\n",
    "    arr_sep=\"\\n\",\n",
    "    exa_sep=\"\\n---\\n\",\n",
    "    eos_token=\"<EOS>\"\n",
    "):\n",
    "    llama_data = []\n",
    "\n",
    "    # Create a mapping from label to index\n",
    "    label_to_index = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    for entry_id, content in dic_training.items():\n",
    "        # Extract perceptions (labels) and encode them as a binary vector\n",
    "        perceptions = content.get(\"perceptions\", [])\n",
    "        label_vector = labels_to_binary(label_list, perceptions)\n",
    "\n",
    "        # Combine train and test examples\n",
    "        examples = content.get(\"example\", {}).get(\"train\", []) + content.get(\"example\", {}).get(\"test\", [])\n",
    "\n",
    "        # Format examples into a single input string\n",
    "        formatted_examples = []\n",
    "        for example in examples:\n",
    "            input_data = f\"{inp_prefix}{format_array(example['input'], arr_sep)}\"\n",
    "            output_data = f\"{out_prefix}{format_array(example['output'], arr_sep)}{eos_token}\"\n",
    "            formatted_examples.append(f\"{input_data}{exa_sep}{output_data}\")\n",
    "\n",
    "        # Combine all examples into one input text\n",
    "        combined_text = exa_sep.join(formatted_examples)\n",
    "\n",
    "        # Add the structured data for fine-tuning\n",
    "        llama_data.append({\n",
    "            \"instruction\": f\"{instruction}\",\n",
    "            #\"instruction\": f\"{instruction}: {', '.join(label_list)}.\",\n",
    "            \"input\": combined_text,\n",
    "            \"output\": label_vector,  # Multi-label as binary vector\n",
    "        })\n",
    "\n",
    "    return llama_data\n",
    "\n",
    "def format_array(array, arr_sep=\"\\n\"):\n",
    "    \"\"\"\n",
    "    Helper function to format a 2D array into a string with row-wise separation.\n",
    "    \"\"\"\n",
    "    return arr_sep.join([\" \".join(map(str, row)) for row in array])\n",
    "\n",
    "def labels_to_binary(label_list, input_labels):\n",
    "    \"\"\"\n",
    "    Convert perceptions into a binary vector based on the label list.\n",
    "    Handles both single strings and lists of strings for input_labels.\n",
    "    \"\"\"\n",
    "    # Ensure input_labels is treated as a list\n",
    "    if isinstance(input_labels, str):\n",
    "        input_labels = [input_labels]\n",
    "    \n",
    "    # Create a set of lowercase input labels\n",
    "    input_set = set(label.lower() for label in input_labels)\n",
    "    \n",
    "    # Generate the binary vector\n",
    "    return [1 if label.lower() in input_set else 0 for label in label_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '',\n",
       " 'input': 'I0 7 7\\n7 7 7\\n0 7 7\\n---\\nO0 0 0 0 7 7 0 7 7\\n0 0 0 7 7 7 7 7 7\\n0 0 0 0 7 7 0 7 7\\n0 7 7 0 7 7 0 7 7\\n7 7 7 7 7 7 7 7 7\\n0 7 7 0 7 7 0 7 7\\n0 0 0 0 7 7 0 7 7\\n0 0 0 7 7 7 7 7 7\\n0 0 0 0 7 7 0 7 7<EOS>\\n---\\nI4 0 4\\n0 0 0\\n0 4 0\\n---\\nO4 0 4 0 0 0 4 0 4\\n0 0 0 0 0 0 0 0 0\\n0 4 0 0 0 0 0 4 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 4 0 4 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 4 0 0 0 0<EOS>\\n---\\nI0 0 0\\n0 0 2\\n2 0 2\\n---\\nO0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 2\\n0 0 0 0 0 0 2 0 2\\n0 0 0 0 0 0 0 0 0\\n0 0 2 0 0 0 0 0 2\\n2 0 2 0 0 0 2 0 2<EOS>\\n---\\nI6 6 0\\n6 0 0\\n0 6 6\\n---\\nO6 6 0 6 6 0 0 0 0\\n6 0 0 6 0 0 0 0 0\\n0 6 6 0 6 6 0 0 0\\n6 6 0 0 0 0 0 0 0\\n6 0 0 0 0 0 0 0 0\\n0 6 6 0 0 0 0 0 0\\n0 0 0 6 6 0 6 6 0\\n0 0 0 6 0 0 6 0 0\\n0 0 0 0 6 6 0 6 6<EOS>\\n---\\nI2 2 2\\n0 0 0\\n0 2 2\\n---\\nO2 2 2 2 2 2 2 2 2\\n0 0 0 0 0 0 0 0 0\\n0 2 2 0 2 2 0 2 2\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 2 2 2 2 2 2\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 2 2 0 2 2<EOS>\\n---\\nI7 0 7\\n7 0 7\\n7 7 0\\n---\\nO7 0 7 0 0 0 7 0 7\\n7 0 7 0 0 0 7 0 7\\n7 7 0 0 0 0 7 7 0\\n7 0 7 0 0 0 7 0 7\\n7 0 7 0 0 0 7 0 7\\n7 7 0 0 0 0 7 7 0\\n7 0 7 7 0 7 0 0 0\\n7 0 7 7 0 7 0 0 0\\n7 7 0 7 7 0 0 0 0<EOS>',\n",
       " 'output': [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction0 = \"\"\n",
    "instruction1 = \"Classify the relationship between the input and output sequences based on perceptions\"\n",
    "\n",
    "# List\n",
    "llama_data = prepare_data_for_multilabel_classification(dic_training,instruction0,label_list)\n",
    "\n",
    "# Dict\n",
    "llama_data_dict = {\n",
    "    \"instruction\": [item[\"instruction\"] for item in llama_data],\n",
    "    \"input\": [item[\"input\"] for item in llama_data],\n",
    "    \"output\": [item[\"output\"] for item in llama_data],\n",
    "}\n",
    "\n",
    "# Dataset\n",
    "llama_data_dataset = Dataset.from_dict(llama_data_dict)\n",
    "\n",
    "llama_data_dataset[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load base model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"barc0/Llama-3.1-ARC-Potpourri-Transduction-8B\"\n",
    ")\n",
    "#model.config.use_cache = False\n",
    "#model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"barc0/Llama-3.1-ARC-Potpourri-Transduction-8B\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BarcHandbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
